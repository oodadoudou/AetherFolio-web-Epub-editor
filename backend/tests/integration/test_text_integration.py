"""TEXTæ–‡ä»¶åŠŸèƒ½é›†æˆæµ‹è¯•"""

import pytest
from pathlib import Path
from httpx import AsyncClient
from fastapi import status
import asyncio
import json
from datetime import datetime


class TestTextIntegration:
    """TEXTæ–‡ä»¶åŠŸèƒ½é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    async def sample_text_files(self, temp_dir: Path):
        """åˆ›å»ºç¤ºä¾‹TEXTæ–‡ä»¶"""
        files = {}
        
        # ç®€å•æ–‡æœ¬æ–‡ä»¶
        simple_file = temp_dir / "simple.txt"
        simple_content = "è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æ–‡æœ¬æ–‡ä»¶ã€‚\nåŒ…å«åŸºæœ¬çš„æ–‡æœ¬å†…å®¹ã€‚"
        simple_file.write_text(simple_content, encoding='utf-8')
        files['simple'] = (simple_file, simple_content)
        
        # Markdownæ–‡ä»¶
        md_file = temp_dir / "document.md"
        md_content = """# æ–‡æ¡£æ ‡é¢˜

è¿™æ˜¯ä¸€ä¸ª**Markdown**æ–‡æ¡£ï¼Œç”¨äºæµ‹è¯•ã€‚

## åŠŸèƒ½åˆ—è¡¨

- [x] æ”¯æŒæ ‡é¢˜
- [x] æ”¯æŒ**ç²—ä½“**å’Œ*æ–œä½“*
- [ ] å¾…å®ŒæˆåŠŸèƒ½

## ä»£ç ç¤ºä¾‹

```python
def hello():
    print("Hello, World!")
```

## é“¾æ¥

[GitHub](https://github.com)

---

æœ€åä¸€è¡Œã€‚"""
        md_file.write_text(md_content, encoding='utf-8')
        files['markdown'] = (md_file, md_content)
        
        # åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡ä»¶
        special_file = temp_dir / "special.txt"
        special_content = """ç‰¹æ®Šå­—ç¬¦æµ‹è¯•æ–‡ä»¶ï¼š

ä¸­æ–‡ï¼šä½ å¥½ä¸–ç•Œ
æ—¥æ–‡ï¼šã“ã‚“ã«ã¡ã¯ä¸–ç•Œ
éŸ©æ–‡ï¼šì•ˆë…•í•˜ì„¸ìš” ì„¸ê³„
Emojiï¼šğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜†ğŸ˜…ğŸ˜‚ğŸ¤£
ç‰¹æ®Šç¬¦å·ï¼šÂ©Â®â„¢â‚¬Â£Â¥Â§Â¶â€ â€¡â€¢â€¦â€°â€±
æ•°å­¦ç¬¦å·ï¼šâˆ€âˆâˆ‚âˆƒâˆ„âˆ…âˆ†âˆ‡âˆˆâˆ‰âˆŠâˆ‹âˆŒâˆâˆâˆ

ç¼–ç¨‹ç¬¦å·ï¼š
{"key": "value", "array": [1, 2, 3]}
<tag>content</tag>
/* comment */
// another comment

è·¯å¾„æµ‹è¯•ï¼š
C:\\Windows\\System32
/usr/local/bin
~/Documents/file.txt

ç‰¹æ®Šå­—ç¬¦ä¸²ï¼š
'single quotes'
"double quotes"
`backticks`
\"escaped quotes\"
\n\t\r\n
ç»“æŸã€‚"""
        special_file.write_text(special_content, encoding='utf-8')
        files['special'] = (special_file, special_content)
        
        return files
    
    @pytest.fixture
    async def replacement_rules_file(self, temp_dir: Path):
        """åˆ›å»ºæ›¿æ¢è§„åˆ™æ–‡ä»¶"""
        rules_file = temp_dir / "rules.txt"
        rules_content = """# åŸºæœ¬æ›¿æ¢è§„åˆ™
æ–‡æœ¬->å†…å®¹
æµ‹è¯•->æ£€éªŒ
ç®€å•->åŸºç¡€

# ç‰¹æ®Šå­—ç¬¦æ›¿æ¢
ä½ å¥½->Hello
ä¸–ç•Œ->World
ğŸ˜€->ğŸŒŸ

# ç¼–ç¨‹ç›¸å…³æ›¿æ¢
print->console.log
def->function
Hello, World!->Hello, Universe!

# æ ‡ç‚¹ç¬¦å·æ›¿æ¢
ã€‚->.
ï¼Œ->,
ï¼š->:"""
        rules_file.write_text(rules_content, encoding='utf-8')
        return rules_file
    
    @pytest.mark.asyncio
    async def test_complete_text_workflow(self, async_client: AsyncClient, sample_text_files, replacement_rules_file):
        """æµ‹è¯•å®Œæ•´çš„TEXTæ–‡ä»¶å·¥ä½œæµç¨‹"""
        simple_file, simple_content = sample_text_files['simple']
        
        # 1. ä¸Šä¼ æ–‡ä»¶
        with open(simple_file, 'rb') as f:
            upload_response = await async_client.post(
                "/api/v1/upload",
                files={"file": ("simple.txt", f, "text/plain")}
            )
        
        assert upload_response.status_code == status.HTTP_200_OK
        upload_data = upload_response.json()
        session_id = upload_data["session_id"]
        assert upload_data["file_type"] == "TEXT"
        
        # 2. è·å–ä¼šè¯ä¿¡æ¯
        session_response = await async_client.get(f"/api/v1/sessions/{session_id}")
        assert session_response.status_code == status.HTTP_200_OK
        session_data = session_response.json()
        assert session_data["session"]["file_type"] == "TEXT"
        assert session_data["session"]["original_filename"] == "simple.txt"
        
        # 3. è¯»å–æ–‡ä»¶å†…å®¹
        read_response = await async_client.get(f"/api/v1/files/{session_id}/content")
        assert read_response.status_code == status.HTTP_200_OK
        read_data = read_response.json()
        assert read_data["content"] == simple_content
        
        # 4. æœç´¢æ–‡æœ¬
        search_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/search",
            json={
                "query": "æ–‡æœ¬",
                "case_sensitive": False,
                "use_regex": False,
                "whole_word": False
            }
        )
        assert search_response.status_code == status.HTTP_200_OK
        search_data = search_response.json()
        assert search_data["success"] is True
        assert len(search_data["results"]) > 0
        
        # 5. æ‰§è¡Œå•æ¬¡æ›¿æ¢
        replace_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/replace",
            json={
                "query": "ç®€å•",
                "replacement": "åŸºç¡€",
                "case_sensitive": False,
                "use_regex": False,
                "whole_word": False
            }
        )
        assert replace_response.status_code == status.HTTP_200_OK
        replace_data = replace_response.json()
        assert replace_data["success"] is True
        assert replace_data["replacements_made"] > 0
        
        # 6. éªŒè¯æ›¿æ¢ç»“æœ
        read_response2 = await async_client.get(f"/api/v1/files/{session_id}/content")
        modified_content = read_response2.json()["content"]
        assert "åŸºç¡€" in modified_content
        assert "ç®€å•" not in modified_content
        
        # 7. æ‰§è¡Œæ‰¹é‡æ›¿æ¢
        with open(replacement_rules_file, 'rb') as f:
            batch_response = await async_client.post(
                f"/api/v1/batch-replace/{session_id}",
                files={"rules_file": ("rules.txt", f, "text/plain")}
            )
        
        assert batch_response.status_code == status.HTTP_200_OK
        batch_data = batch_response.json()
        assert batch_data["success"] is True
        task_id = batch_data["task_id"]
        
        # 8. ç›‘æ§æ‰¹é‡æ›¿æ¢è¿›åº¦
        max_attempts = 30
        for attempt in range(max_attempts):
            progress_response = await async_client.get(f"/api/v1/batch-replace/{session_id}/progress/{task_id}")
            if progress_response.status_code == status.HTTP_200_OK:
                progress_data = progress_response.json()
                if progress_data.get("status") == "completed":
                    break
            await asyncio.sleep(1)
        else:
            pytest.fail("æ‰¹é‡æ›¿æ¢æœªåœ¨é¢„æœŸæ—¶é—´å†…å®Œæˆ")
        
        # 9. éªŒè¯æ‰¹é‡æ›¿æ¢ç»“æœ
        read_response3 = await async_client.get(f"/api/v1/files/{session_id}/content")
        final_content = read_response3.json()["content"]
        assert "å†…å®¹" in final_content  # "æ–‡æœ¬" -> "å†…å®¹"
        assert "æ£€éªŒ" in final_content  # "æµ‹è¯•" -> "æ£€éªŒ"
        
        # 10. å¯¼å‡ºæ–‡ä»¶
        export_response = await async_client.get(f"/api/v1/export/{session_id}")
        assert export_response.status_code == status.HTTP_200_OK
        exported_content = export_response.content.decode('utf-8')
        assert exported_content == final_content
        
        # 11. åˆ é™¤ä¼šè¯
        delete_response = await async_client.delete(f"/api/v1/sessions/{session_id}")
        assert delete_response.status_code == status.HTTP_200_OK
        
        # 12. éªŒè¯ä¼šè¯å·²åˆ é™¤
        final_session_response = await async_client.get(f"/api/v1/sessions/{session_id}")
        assert final_session_response.status_code == status.HTTP_404_NOT_FOUND
    
    @pytest.mark.asyncio
    async def test_markdown_file_workflow(self, async_client: AsyncClient, sample_text_files, replacement_rules_file):
        """æµ‹è¯•Markdownæ–‡ä»¶å·¥ä½œæµç¨‹"""
        md_file, md_content = sample_text_files['markdown']
        
        # ä¸Šä¼ Markdownæ–‡ä»¶
        with open(md_file, 'rb') as f:
            upload_response = await async_client.post(
                "/api/v1/upload",
                files={"file": ("document.md", f, "text/markdown")}
            )
        
        assert upload_response.status_code == status.HTTP_200_OK
        session_id = upload_response.json()["session_id"]
        
        # éªŒè¯Markdownå†…å®¹
        read_response = await async_client.get(f"/api/v1/files/{session_id}/content")
        content = read_response.json()["content"]
        assert "# æ–‡æ¡£æ ‡é¢˜" in content
        assert "**Markdown**" in content
        assert "```python" in content
        
        # æœç´¢Markdownç‰¹å®šå†…å®¹
        search_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/search",
            json={
                "query": "def hello",
                "case_sensitive": False,
                "use_regex": False,
                "whole_word": False
            }
        )
        assert search_response.status_code == status.HTTP_200_OK
        assert len(search_response.json()["results"]) > 0
        
        # æ‰§è¡Œæ‰¹é‡æ›¿æ¢
        with open(replacement_rules_file, 'rb') as f:
            batch_response = await async_client.post(
                f"/api/v1/batch-replace/{session_id}",
                files={"rules_file": ("rules.txt", f, "text/plain")}
            )
        
        assert batch_response.status_code == status.HTTP_200_OK
        task_id = batch_response.json()["task_id"]
        
        # ç­‰å¾…å®Œæˆ
        await asyncio.sleep(3)
        
        # éªŒè¯æ›¿æ¢ç»“æœ
        read_response2 = await async_client.get(f"/api/v1/files/{session_id}/content")
        modified_content = read_response2.json()["content"]
        assert "function hello" in modified_content  # "def" -> "function"
        assert "console.log" in modified_content  # "print" -> "console.log"
        assert "Hello, Universe!" in modified_content  # "Hello, World!" -> "Hello, Universe!"
        
        # å¯¼å‡ºMarkdownæ–‡ä»¶
        export_response = await async_client.get(f"/api/v1/export/{session_id}")
        assert export_response.status_code == status.HTTP_200_OK
        assert "document.md" in export_response.headers["content-disposition"]
    
    @pytest.mark.asyncio
    async def test_special_characters_workflow(self, async_client: AsyncClient, sample_text_files, replacement_rules_file):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦æ–‡ä»¶å·¥ä½œæµç¨‹"""
        special_file, special_content = sample_text_files['special']
        
        # ä¸Šä¼ åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡ä»¶
        with open(special_file, 'rb') as f:
            upload_response = await async_client.post(
                "/api/v1/upload",
                files={"file": ("special.txt", f, "text/plain")}
            )
        
        assert upload_response.status_code == status.HTTP_200_OK
        session_id = upload_response.json()["session_id"]
        
        # éªŒè¯ç‰¹æ®Šå­—ç¬¦æ­£ç¡®è¯»å–
        read_response = await async_client.get(f"/api/v1/files/{session_id}/content")
        content = read_response.json()["content"]
        assert "ä½ å¥½ä¸–ç•Œ" in content
        assert "ğŸ˜€ğŸ˜ƒğŸ˜„" in content
        assert "âˆ€âˆâˆ‚âˆƒ" in content
        assert "Â©Â®â„¢â‚¬" in content
        
        # æœç´¢Unicodeå­—ç¬¦
        search_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/search",
            json={
                "query": "ğŸ˜€",
                "case_sensitive": False,
                "use_regex": False,
                "whole_word": False
            }
        )
        assert search_response.status_code == status.HTTP_200_OK
        assert len(search_response.json()["results"]) > 0
        
        # æ‰§è¡ŒåŒ…å«Unicodeçš„æ‰¹é‡æ›¿æ¢
        with open(replacement_rules_file, 'rb') as f:
            batch_response = await async_client.post(
                f"/api/v1/batch-replace/{session_id}",
                files={"rules_file": ("rules.txt", f, "text/plain")}
            )
        
        assert batch_response.status_code == status.HTTP_200_OK
        
        # ç­‰å¾…å®Œæˆ
        await asyncio.sleep(3)
        
        # éªŒè¯Unicodeæ›¿æ¢ç»“æœ
        read_response2 = await async_client.get(f"/api/v1/files/{session_id}/content")
        modified_content = read_response2.json()["content"]
        assert "Hello" in modified_content  # "ä½ å¥½" -> "Hello"
        assert "World" in modified_content  # "ä¸–ç•Œ" -> "World"
        assert "ğŸŒŸ" in modified_content  # "ğŸ˜€" -> "ğŸŒŸ"
        
        # å¯¼å‡ºå¹¶éªŒè¯ç‰¹æ®Šå­—ç¬¦ä¿æŒå®Œæ•´
        export_response = await async_client.get(f"/api/v1/export/{session_id}")
        assert export_response.status_code == status.HTTP_200_OK
        exported_content = export_response.content.decode('utf-8')
        assert "ğŸŒŸ" in exported_content
        assert "Hello" in exported_content
        assert "World" in exported_content
    
    @pytest.mark.asyncio
    async def test_multiple_files_concurrent_processing(self, async_client: AsyncClient, sample_text_files, replacement_rules_file):
        """æµ‹è¯•å¤šæ–‡ä»¶å¹¶å‘å¤„ç†"""
        session_ids = []
        
        # å¹¶å‘ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
        upload_tasks = []
        for file_type, (file_path, content) in sample_text_files.items():
            with open(file_path, 'rb') as f:
                file_content = f.read()
            
            async def upload_file(file_content, filename):
                return await async_client.post(
                    "/api/v1/upload",
                    files={"file": (filename, file_content, "text/plain")}
                )
            
            task = upload_file(file_content, file_path.name)
            upload_tasks.append(task)
        
        upload_responses = await asyncio.gather(*upload_tasks)
        
        # éªŒè¯æ‰€æœ‰ä¸Šä¼ æˆåŠŸ
        for response in upload_responses:
            assert response.status_code == status.HTTP_200_OK
            session_ids.append(response.json()["session_id"])
        
        # å¹¶å‘æ‰§è¡Œæ‰¹é‡æ›¿æ¢
        batch_tasks = []
        for session_id in session_ids:
            with open(replacement_rules_file, 'rb') as f:
                rules_content = f.read()
            
            async def batch_replace(session_id, rules_content):
                return await async_client.post(
                    f"/api/v1/batch-replace/{session_id}",
                    files={"rules_file": ("rules.txt", rules_content, "text/plain")}
                )
            
            task = batch_replace(session_id, rules_content)
            batch_tasks.append(task)
        
        batch_responses = await asyncio.gather(*batch_tasks)
        
        # éªŒè¯æ‰€æœ‰æ‰¹é‡æ›¿æ¢å¯åŠ¨æˆåŠŸ
        task_ids = []
        for response in batch_responses:
            assert response.status_code == status.HTTP_200_OK
            task_ids.append(response.json()["task_id"])
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await asyncio.sleep(5)
        
        # å¹¶å‘éªŒè¯æ‰€æœ‰æ–‡ä»¶çš„å¤„ç†ç»“æœ
        read_tasks = []
        for session_id in session_ids:
            task = async_client.get(f"/api/v1/files/{session_id}/content")
            read_tasks.append(task)
        
        read_responses = await asyncio.gather(*read_tasks)
        
        # éªŒè¯æ‰€æœ‰æ–‡ä»¶éƒ½è¢«æ­£ç¡®å¤„ç†
        for response in read_responses:
            assert response.status_code == status.HTTP_200_OK
            content = response.json()["content"]
            # éªŒè¯è‡³å°‘æœ‰ä¸€äº›æ›¿æ¢å‘ç”Ÿ
            assert "å†…å®¹" in content or "æ£€éªŒ" in content or "Hello" in content
        
        # å¹¶å‘å¯¼å‡ºæ‰€æœ‰æ–‡ä»¶
        export_tasks = []
        for session_id in session_ids:
            task = async_client.get(f"/api/v1/export/{session_id}")
            export_tasks.append(task)
        
        export_responses = await asyncio.gather(*export_tasks)
        
        # éªŒè¯æ‰€æœ‰å¯¼å‡ºæˆåŠŸ
        for response in export_responses:
            assert response.status_code == status.HTTP_200_OK
            assert "content-disposition" in response.headers
        
        # æ¸…ç†ï¼šåˆ é™¤æ‰€æœ‰ä¼šè¯
        delete_tasks = []
        for session_id in session_ids:
            task = async_client.delete(f"/api/v1/sessions/{session_id}")
            delete_tasks.append(task)
        
        delete_responses = await asyncio.gather(*delete_tasks)
        
        # éªŒè¯æ‰€æœ‰åˆ é™¤æˆåŠŸ
        for response in delete_responses:
            assert response.status_code == status.HTTP_200_OK
    
    @pytest.mark.asyncio
    async def test_large_file_processing(self, async_client: AsyncClient, temp_dir: Path, replacement_rules_file):
        """æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†"""
        # åˆ›å»ºå¤§æ–‡ä»¶ï¼ˆçº¦1MBï¼‰
        large_file = temp_dir / "large.txt"
        base_content = "è¿™æ˜¯ä¸€è¡Œé‡å¤çš„å†…å®¹ï¼Œç”¨äºæµ‹è¯•å¤§æ–‡ä»¶å¤„ç†åŠŸèƒ½ã€‚åŒ…å«æ–‡æœ¬å’Œæµ‹è¯•å…³é”®è¯ã€‚\n"
        large_content = base_content * 20000  # çº¦1MB
        large_file.write_text(large_content, encoding='utf-8')
        
        # ä¸Šä¼ å¤§æ–‡ä»¶
        with open(large_file, 'rb') as f:
            upload_response = await async_client.post(
                "/api/v1/upload",
                files={"file": ("large.txt", f, "text/plain")}
            )
        
        assert upload_response.status_code == status.HTTP_200_OK
        session_id = upload_response.json()["session_id"]
        
        # éªŒè¯å¤§æ–‡ä»¶å†…å®¹æ­£ç¡®è¯»å–
        read_response = await async_client.get(f"/api/v1/files/{session_id}/content")
        assert read_response.status_code == status.HTTP_200_OK
        content = read_response.json()["content"]
        assert len(content) == len(large_content)
        
        # åœ¨å¤§æ–‡ä»¶ä¸­æœç´¢
        search_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/search",
            json={
                "query": "æµ‹è¯•",
                "case_sensitive": False,
                "use_regex": False,
                "whole_word": False
            }
        )
        assert search_response.status_code == status.HTTP_200_OK
        search_results = search_response.json()["results"]
        assert len(search_results) > 10000  # åº”è¯¥æ‰¾åˆ°å¾ˆå¤šåŒ¹é…
        
        # æ‰§è¡Œå¤§æ–‡ä»¶æ‰¹é‡æ›¿æ¢
        with open(replacement_rules_file, 'rb') as f:
            batch_response = await async_client.post(
                f"/api/v1/batch-replace/{session_id}",
                files={"rules_file": ("rules.txt", f, "text/plain")}
            )
        
        assert batch_response.status_code == status.HTTP_200_OK
        
        # ç­‰å¾…å¤§æ–‡ä»¶å¤„ç†å®Œæˆï¼ˆå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
        await asyncio.sleep(10)
        
        # éªŒè¯å¤§æ–‡ä»¶æ›¿æ¢ç»“æœ
        read_response2 = await async_client.get(f"/api/v1/files/{session_id}/content")
        modified_content = read_response2.json()["content"]
        assert "æ£€éªŒ" in modified_content  # "æµ‹è¯•" -> "æ£€éªŒ"
        assert "å†…å®¹" in modified_content  # "æ–‡æœ¬" -> "å†…å®¹"
        
        # å¯¼å‡ºå¤§æ–‡ä»¶
        export_response = await async_client.get(f"/api/v1/export/{session_id}")
        assert export_response.status_code == status.HTTP_200_OK
        exported_content = export_response.content.decode('utf-8')
        assert len(exported_content) > 500000  # ç¡®ä¿å¯¼å‡ºçš„æ˜¯å®Œæ•´æ–‡ä»¶
    
    @pytest.mark.asyncio
    async def test_regex_search_replace_integration(self, async_client: AsyncClient, temp_dir: Path):
        """æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼æœç´¢æ›¿æ¢é›†æˆ"""
        # åˆ›å»ºåŒ…å«å„ç§æ¨¡å¼çš„æµ‹è¯•æ–‡ä»¶
        regex_file = temp_dir / "regex_test.txt"
        regex_content = """æ­£åˆ™è¡¨è¾¾å¼æµ‹è¯•æ–‡ä»¶ï¼š

ç”µè¯å·ç ï¼š
138-1234-5678
139-8765-4321
186-9999-0000

é‚®ç®±åœ°å€ï¼š
user@example.com
test.email@domain.org
admin@company.co.uk

æ—¥æœŸæ ¼å¼ï¼š
2024-01-15
2023-12-31
2022-06-30

æ—¶é—´æ ¼å¼ï¼š
14:30:25
09:15:00
23:59:59

IPåœ°å€ï¼š
192.168.1.1
10.0.0.1
172.16.0.100

æ•°å­—åºåˆ—ï¼š
ID001, ID002, ID003
NUM123, NUM456, NUM789

ç»“æŸã€‚"""
        regex_file.write_text(regex_content, encoding='utf-8')
        
        # ä¸Šä¼ æ–‡ä»¶
        with open(regex_file, 'rb') as f:
            upload_response = await async_client.post(
                "/api/v1/upload",
                files={"file": ("regex_test.txt", f, "text/plain")}
            )
        
        session_id = upload_response.json()["session_id"]
        
        # æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼æœç´¢
        regex_tests = [
            (r"\d{3}-\d{4}-\d{4}", "ç”µè¯å·ç æ¨¡å¼"),
            (r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", "é‚®ç®±æ¨¡å¼"),
            (r"\d{4}-\d{2}-\d{2}", "æ—¥æœŸæ¨¡å¼"),
            (r"\d{2}:\d{2}:\d{2}", "æ—¶é—´æ¨¡å¼"),
            (r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}", "IPåœ°å€æ¨¡å¼"),
            (r"ID\d{3}", "IDåºåˆ—æ¨¡å¼")
        ]
        
        for pattern, description in regex_tests:
            search_response = await async_client.post(
                f"/api/v1/search-replace/{session_id}/search",
                json={
                    "query": pattern,
                    "case_sensitive": False,
                    "use_regex": True,
                    "whole_word": False
                }
            )
            
            assert search_response.status_code == status.HTTP_200_OK
            results = search_response.json()["results"]
            assert len(results) > 0, f"{description} åº”è¯¥æ‰¾åˆ°åŒ¹é…é¡¹"
        
        # æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢
        replace_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/replace",
            json={
                "query": r"(\d{3})-(\d{4})-(\d{4})",
                "replacement": r"(\1) \2-\3",
                "case_sensitive": False,
                "use_regex": True,
                "whole_word": False
            }
        )
        
        assert replace_response.status_code == status.HTTP_200_OK
        assert replace_response.json()["replacements_made"] > 0
        
        # éªŒè¯æ­£åˆ™æ›¿æ¢ç»“æœ
        read_response = await async_client.get(f"/api/v1/files/{session_id}/content")
        modified_content = read_response.json()["content"]
        assert "(138) 1234-5678" in modified_content
        assert "(139) 8765-4321" in modified_content
        assert "138-1234-5678" not in modified_content
    
    @pytest.mark.asyncio
    async def test_error_recovery_and_rollback(self, async_client: AsyncClient, temp_dir: Path):
        """æµ‹è¯•é”™è¯¯æ¢å¤å’Œå›æ»šæœºåˆ¶"""
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_file = temp_dir / "error_test.txt"
        original_content = "é”™è¯¯æ¢å¤æµ‹è¯•æ–‡ä»¶\nåŒ…å«åŸå§‹å†…å®¹\nç”¨äºæµ‹è¯•é”™è¯¯å¤„ç†"
        test_file.write_text(original_content, encoding='utf-8')
        
        # ä¸Šä¼ æ–‡ä»¶
        with open(test_file, 'rb') as f:
            upload_response = await async_client.post(
                "/api/v1/upload",
                files={"file": ("error_test.txt", f, "text/plain")}
            )
        
        session_id = upload_response.json()["session_id"]
        
        # éªŒè¯åŸå§‹å†…å®¹
        read_response = await async_client.get(f"/api/v1/files/{session_id}/content")
        assert read_response.json()["content"] == original_content
        
        # å°è¯•æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼æœç´¢
        invalid_search_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/search",
            json={
                "query": "[invalid regex",  # æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼
                "case_sensitive": False,
                "use_regex": True,
                "whole_word": False
            }
        )
        
        # åº”è¯¥è¿”å›é”™è¯¯ä½†ä¸å½±å“æ–‡ä»¶å†…å®¹
        assert invalid_search_response.status_code == status.HTTP_400_BAD_REQUEST
        
        # éªŒè¯æ–‡ä»¶å†…å®¹æœªè¢«ç ´å
        read_response2 = await async_client.get(f"/api/v1/files/{session_id}/content")
        assert read_response2.json()["content"] == original_content
        
        # å°è¯•æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢
        invalid_replace_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/replace",
            json={
                "query": "[another invalid regex",
                "replacement": "replacement",
                "case_sensitive": False,
                "use_regex": True,
                "whole_word": False
            }
        )
        
        # åº”è¯¥è¿”å›é”™è¯¯
        assert invalid_replace_response.status_code == status.HTTP_400_BAD_REQUEST
        
        # éªŒè¯æ–‡ä»¶å†…å®¹ä»ç„¶å®Œæ•´
        read_response3 = await async_client.get(f"/api/v1/files/{session_id}/content")
        assert read_response3.json()["content"] == original_content
        
        # åˆ›å»ºæ— æ•ˆçš„æ‰¹é‡æ›¿æ¢è§„åˆ™æ–‡ä»¶
        invalid_rules_file = temp_dir / "invalid_rules.txt"
        invalid_rules_content = """# åŒ…å«æ— æ•ˆæ­£åˆ™è¡¨è¾¾å¼çš„è§„åˆ™
[invalid->valid
(unclosed->group
*invalid->pattern"""
        invalid_rules_file.write_text(invalid_rules_content, encoding='utf-8')
        
        # å°è¯•ä½¿ç”¨æ— æ•ˆè§„åˆ™è¿›è¡Œæ‰¹é‡æ›¿æ¢
        with open(invalid_rules_file, 'rb') as f:
            invalid_batch_response = await async_client.post(
                f"/api/v1/batch-replace/{session_id}",
                files={"rules_file": ("invalid_rules.txt", f, "text/plain")}
            )
        
        # æ‰¹é‡æ›¿æ¢å¯èƒ½å¯åŠ¨ä½†åº”è¯¥å¤±è´¥
        if invalid_batch_response.status_code == status.HTTP_200_OK:
            # ç­‰å¾…å¤„ç†å®Œæˆ
            await asyncio.sleep(3)
            
            # éªŒè¯æ–‡ä»¶å†…å®¹æœªè¢«ç ´å
            read_response4 = await async_client.get(f"/api/v1/files/{session_id}/content")
            final_content = read_response4.json()["content"]
            # æ–‡ä»¶åº”è¯¥ä¿æŒåŸæ ·æˆ–åªæœ‰éƒ¨åˆ†æœ‰æ•ˆè§„åˆ™è¢«åº”ç”¨
            assert "é”™è¯¯æ¢å¤æµ‹è¯•æ–‡ä»¶" in final_content
        
        # æœ€ç»ˆéªŒè¯ä¼šè¯ä»ç„¶å¯ç”¨
        session_response = await async_client.get(f"/api/v1/sessions/{session_id}")
        assert session_response.status_code == status.HTTP_200_OK
    
    @pytest.mark.asyncio
    async def test_performance_monitoring(self, async_client: AsyncClient, temp_dir: Path):
        """æµ‹è¯•æ€§èƒ½ç›‘æ§"""
        # åˆ›å»ºä¸­ç­‰å¤§å°çš„æ–‡ä»¶ç”¨äºæ€§èƒ½æµ‹è¯•
        perf_file = temp_dir / "performance.txt"
        base_line = "æ€§èƒ½æµ‹è¯•è¡Œï¼ŒåŒ…å«æµ‹è¯•å…³é”®è¯å’Œæ–‡æœ¬å†…å®¹ï¼Œç”¨äºæ›¿æ¢æ“ä½œã€‚\n"
        perf_content = base_line * 10000  # çº¦500KB
        perf_file.write_text(perf_content, encoding='utf-8')
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.now()
        
        # ä¸Šä¼ æ–‡ä»¶
        with open(perf_file, 'rb') as f:
            upload_response = await async_client.post(
                "/api/v1/upload",
                files={"file": ("performance.txt", f, "text/plain")}
            )
        
        upload_time = datetime.now()
        assert upload_response.status_code == status.HTTP_200_OK
        session_id = upload_response.json()["session_id"]
        
        # è¯»å–æ–‡ä»¶ï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰
        read_response = await async_client.get(f"/api/v1/files/{session_id}/content")
        read_time = datetime.now()
        assert read_response.status_code == status.HTTP_200_OK
        
        # æœç´¢æ“ä½œï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰
        search_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/search",
            json={
                "query": "æµ‹è¯•",
                "case_sensitive": False,
                "use_regex": False,
                "whole_word": False
            }
        )
        search_time = datetime.now()
        assert search_response.status_code == status.HTTP_200_OK
        
        # æ›¿æ¢æ“ä½œï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰
        replace_response = await async_client.post(
            f"/api/v1/search-replace/{session_id}/replace",
            json={
                "query": "æµ‹è¯•",
                "replacement": "æ£€éªŒ",
                "case_sensitive": False,
                "use_regex": False,
                "whole_word": False
            }
        )
        replace_time = datetime.now()
        assert replace_response.status_code == status.HTTP_200_OK
        
        # å¯¼å‡ºæ“ä½œï¼ˆæ€§èƒ½æµ‹è¯•ï¼‰
        export_response = await async_client.get(f"/api/v1/export/{session_id}")
        export_time = datetime.now()
        assert export_response.status_code == status.HTTP_200_OK
        
        # è®¡ç®—å„æ“ä½œè€—æ—¶
        upload_duration = (upload_time - start_time).total_seconds()
        read_duration = (read_time - upload_time).total_seconds()
        search_duration = (search_time - read_time).total_seconds()
        replace_duration = (replace_time - search_time).total_seconds()
        export_duration = (export_time - replace_time).total_seconds()
        total_duration = (export_time - start_time).total_seconds()
        
        # æ€§èƒ½æ–­è¨€ï¼ˆè¿™äº›é˜ˆå€¼å¯èƒ½éœ€è¦æ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´ï¼‰
        assert upload_duration < 10.0, f"ä¸Šä¼ è€—æ—¶è¿‡é•¿: {upload_duration}ç§’"
        assert read_duration < 5.0, f"è¯»å–è€—æ—¶è¿‡é•¿: {read_duration}ç§’"
        assert search_duration < 5.0, f"æœç´¢è€—æ—¶è¿‡é•¿: {search_duration}ç§’"
        assert replace_duration < 10.0, f"æ›¿æ¢è€—æ—¶è¿‡é•¿: {replace_duration}ç§’"
        assert export_duration < 5.0, f"å¯¼å‡ºè€—æ—¶è¿‡é•¿: {export_duration}ç§’"
        assert total_duration < 30.0, f"æ€»è€—æ—¶è¿‡é•¿: {total_duration}ç§’"
        
        # è®°å½•æ€§èƒ½æ•°æ®ï¼ˆç”¨äºç›‘æ§ï¼‰
        print(f"\næ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"ä¸Šä¼ : {upload_duration:.2f}ç§’")
        print(f"è¯»å–: {read_duration:.2f}ç§’")
        print(f"æœç´¢: {search_duration:.2f}ç§’")
        print(f"æ›¿æ¢: {replace_duration:.2f}ç§’")
        print(f"å¯¼å‡º: {export_duration:.2f}ç§’")
        print(f"æ€»è®¡: {total_duration:.2f}ç§’")